---
title: "Machine Learning: clasificaci贸n de vino"
author: "Carlos Gallego"
date: '2022-02-27'
slug: 'ML'
categories:
  - clasificacion
tags: 
  - clasificacion
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE,cache =  T)
```

```{r include=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(dbplyr)))
suppressWarnings(suppressPackageStartupMessages(library(inspectdf)))
suppressWarnings(suppressPackageStartupMessages(library(mvoutlier)))
suppressWarnings(suppressPackageStartupMessages(library(foreign)))
suppressWarnings(suppressPackageStartupMessages(library(data.table)))
suppressWarnings(suppressPackageStartupMessages(library(DescTools)))
suppressWarnings(suppressPackageStartupMessages(library(dplyr)))
suppressWarnings(suppressPackageStartupMessages(library(tidyr)))
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))
suppressWarnings(suppressPackageStartupMessages(library(Hmisc)))
suppressWarnings(suppressPackageStartupMessages(library(funModeling)))
suppressWarnings(suppressPackageStartupMessages(library(skimr)))
suppressWarnings(suppressPackageStartupMessages(library(nortest)))
suppressWarnings(suppressPackageStartupMessages(library(lmtest)))
suppressWarnings(suppressPackageStartupMessages(library(tseries)))
suppressWarnings(suppressPackageStartupMessages(library(MASS)))
suppressWarnings(suppressPackageStartupMessages(library(car)))
suppressWarnings(suppressPackageStartupMessages(library(leaps)))
suppressWarnings(suppressPackageStartupMessages(library(Metrics)))
suppressWarnings(suppressPackageStartupMessages(library(carData)))
suppressWarnings(suppressPackageStartupMessages(library(rpart)))
suppressWarnings(suppressPackageStartupMessages(library(ggplot2)))
suppressWarnings(suppressPackageStartupMessages(library(rcompanion)))
suppressWarnings(suppressPackageStartupMessages(library(glmnet)))
suppressWarnings(suppressPackageStartupMessages(library(boot)))
suppressWarnings(suppressPackageStartupMessages(library(PerformanceAnalytics)))
suppressWarnings(suppressPackageStartupMessages(library(corrplot)))
suppressWarnings(suppressPackageStartupMessages(library(corrr)))
suppressWarnings(suppressPackageStartupMessages(library(lme4)))
suppressWarnings(suppressPackageStartupMessages(library(Matrix)))
suppressWarnings(suppressPackageStartupMessages(library(missForest)))
suppressWarnings(suppressPackageStartupMessages(library(doParallel)))
suppressWarnings(suppressPackageStartupMessages(library(funModeling)))
suppressWarnings(suppressPackageStartupMessages(library(DMwR2)))
suppressWarnings(suppressPackageStartupMessages(library(sampling)))
suppressWarnings(suppressPackageStartupMessages(library(mice)))
suppressWarnings(suppressPackageStartupMessages(library(arules)))
suppressWarnings(suppressPackageStartupMessages(library(codebook)))
suppressWarnings(suppressPackageStartupMessages(library(DMwR)))
suppressWarnings(suppressPackageStartupMessages(library(ROCR)))
suppressWarnings(suppressPackageStartupMessages(library(pROC)))
suppressWarnings(suppressPackageStartupMessages(library(caret)))
suppressWarnings(suppressPackageStartupMessages(library(C50)))
suppressWarnings(suppressPackageStartupMessages(library(gmodels)))
suppressWarnings(suppressPackageStartupMessages(library(keras)))
suppressWarnings(suppressPackageStartupMessages(library(binda)))
suppressWarnings(suppressPackageStartupMessages(library(arules)))
suppressWarnings(suppressPackageStartupMessages(library(foreign)))
suppressWarnings(suppressPackageStartupMessages(library(fastAdaboost)))
suppressWarnings(suppressPackageStartupMessages(library(readxl)))
suppressWarnings(suppressPackageStartupMessages(library(maxLik)))
suppressWarnings(suppressPackageStartupMessages(library(plotly)))
suppressWarnings(suppressPackageStartupMessages(library(gapminder)))
suppressWarnings(suppressPackageStartupMessages(library(DT)))

```


# 驴Puedes distinguir los vinos blancos de los vinos tintos en una cata a ciegas? 驴Est谩s seguro? 

Obviamente existen diferencias notorias entre ambos tipos de vino y, a煤n sin ser un sommelier, podr铆as distinguirlos f谩cilmente. La cuesti贸n es con qu茅 **porcentaje de acierto** podr铆as hacerlo. Y es que la prueba se complicar铆a si nos dieran a probar vinos blancos con caracter铆sticas de tintos y viceversa. Sin embargo, existen t茅cnicas de machine learning que permiten que una m谩quina o un algoritmo clasifique el vino en blanco o tinto, con un porcentaje de acierto muy cercano al 100%. 隆Vamos a verlo!

![](images/destacada-nota-vino.jpg)

El concepto de aprendizaje autom谩tico, comunmente conocido como *machine learning*, se refiere al conjunto de algoritmos que nos permiten identificar patrones presentes en los datos y crear estructuras (modelos) que los representen con ellos. Una vez generados, los modelos se pueden utilizar para realizar predicciones. Es importante mencionar que los sistemas de aprendizaje autom谩tico solo pueden almacenar patrones presentes en los datos con los que est谩n entrenados, por lo que solo pueden reconocer lo que han visto antes. 

Los algoritmos de dichas predicciones pueden ser distintos dependiendo de si estamos ante un problema de **clasificaci贸n**, donde el resultado es una clase con un n煤mero limitado de categor铆as (blanco/tinto, s铆/no, excelente/bueno/malo, etc.), o un problema de **regresi贸n**, donde el resultado es un valor num茅rico entre un infinito de posibles resultados. Los problemas de regresi贸n suelen presentar resultados m谩s discretos que los problemas de clasificaci贸n. 


En este punto, si no est谩s familiarizado con los conceptos de *machine learning* se recomienda ver el [anexo I](#anexo1) para conocer las distintas etapas que tienen lugar en dichos procesos, as铆 c贸mo conocer el significado de algunos elementos b谩sicos para la comprensi贸n de los modelos. De igual manera, puedes continuar leyendo y obtendr谩s una aproximaci贸n a modelos predictivos mediante t茅nicas de aprendizaje autom谩tico.  

Contenido:

1. [Definici贸n del problema](#problema) .

2. [Exploraci贸n y sumario de datos](#caracteristicas).

3. [Correlaciones](#correlaciones).

4. [Algoritmos de clasificaci贸n: Divisi贸n, ajuste y evaluaci贸n](#algoritmos).

5. [驴Qu茅 importancia otorga cada modelo a cada variable?](#importancia)

6. [Comparativa de modelos](#metricas).

[Anexo I: Etapas en un proceso de machine learning](#anexo1).

[Anexo II: Dificultades habituales en el preprocesado](#anexo2).




# 1. Definici贸n del problema {#problema}

En todo proceso de *machine learning* es necesario definir el problema y tener claro qu茅 queremos predecir. En nuestro caso, se trata de un problema de clasificaci贸n. En concreto, queremos desarrollar distintos modelos que sean capaces de predecir si se trata de un vino tinto o un vino blanco dadas las caracter铆sticas qu铆micas del vino.
Para ello, explotaremos un conjunto de datos con las caracter铆sticas de 6497 vinos que hemos encontrado en la siguiente web : [https://www.kaggle.com/aleixdorca/wine-quality]

```{r carga datos y nombres v., message=FALSE, warning=FALSE, include=FALSE}
winequality <- read_csv("C:/Users/Usuario/Downloads/winequality.csv")

#Ahora duplicamos el dataset porque realizaremos modificaciones sobre el dataset y, personalmente, quiero tener un dataset guardado como original por si tengo que comparar alguna modificaci贸n.
original= winequality


colnames(winequality) <- c("acidez_fija", "acidez_variable", "acido_citrico","azucar_residual", "cloruros","dioxido_azufre_libre",
"dioxido_azufre_total","densidad", "pH","sulfatos", "alcohol","calidad", "bueno","color")   
winequality$color= as.factor(winequality$color)
winequality$bueno = as.factor(winequality$bueno)

```


# 2. Exploraci贸n y sumario de datos {#caracteristicas}

Una vez hemos definido el problema, el siguiente paso es tratar de entender los datos. Para facilitar dicho proceso podemos hacernos preguntas c贸mo: 驴De qu茅 datos disponemos? 驴Cu谩les son las caracter铆sticas de 茅stos? 驴C贸mo se correlacionan las distintas variables? 驴Es necesario realizar alguna transformaci贸n a los datos? 

Por ello, visualizamos la tabla de datos. Podemos filtrar por columnas, canviarlas de posici贸n e incluso descargarnos los datos directamente.  


```{r tabla, echo=FALSE}
datatable(winequality,extensions = c('Buttons', 'ColReorder'), filter = "top", options = list(colReorder = TRUE,  pageLength = 8, dom = 'Bfrtip', buttons = c('copy', 'csv', 'excel', 'pdf', 'print'), scrollX = TRUE)) 
```


Podemos observar que se trata de un conjunto de datos de 6497 observaciones y 14 variables, 12 de ellas son num茅ricas y las otras dos son categ贸ricas.

Tambi茅n podemos advertir la media de cada variable, junto a su desvicaci贸n t铆pica, su valor m铆nimo y m谩ximo, sus cuantiles y si presentan datos ausentes o no. En este caso, ninguna variable presenta datos faltantes.
```{r resumen, echo=FALSE}
skim(winequality)
```

Observamos un peque帽o histograma de las variables num茅ricas y un gr谩fico que muestra la frecuencia de las variables categ贸ricas. En el caso de la variable "bueno" el 1 significa que dicho vino s铆 es considerado bueno, de lo contrario el valor asignado es 0.
```{r peq histograma de las variables, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}
library(funModeling)
plot_num(winequality)
```

```{r freq de las variables, echo=FALSE, message=FALSE, warning=FALSE}
freq(winequality, plot=T)
```
A continuaci贸n podemos observar las diferencias en las caracter铆sticas de los vinos blancos y los vinos rojos o tintos, primero mediante una tabla que resume la media de cada estad铆stico dependiendo del tipo de vino, y en segundo lugar mediante un diagrama de cajas de ambos grupos.

```{r dif_colores, echo=FALSE, message=FALSE, warning=FALSE}
dif_color <-
  aggregate(original,
            by = list(original$color),
            FUN = mean)
dif_color2= round(dif_color[2:14], digits= 3)
dif_color= dif_color%>%dplyr::select(Group.1)
dif_color= cbind(dif_color, dif_color2)

datatable(dif_color, extensions =  'ColReorder', filter = "top", options = list(colReorder = TRUE,  scrollX = TRUE)) 
```

```{r boxplots, echo=FALSE, message=FALSE, warning=FALSE}
library(cowplot)
a=ggplot(data = winequality, aes(color, acidez_fija, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

b=ggplot(data = winequality, aes(color, acidez_variable, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

c=ggplot(data = winequality, aes(color, acido_citrico, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

d=ggplot(data = winequality, aes(color, azucar_residual, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

e=ggplot(data = winequality, aes(color, cloruros, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

f=ggplot(data = winequality, aes(color, dioxido_azufre_libre, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

g=ggplot(data = winequality, aes(color, dioxido_azufre_total, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

h=ggplot(data = winequality, aes(color, densidad, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

i=ggplot(data = winequality, aes(color, pH, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

j=ggplot(data = winequality, aes(color, sulfatos, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

k=ggplot(data = winequality, aes(color, alcohol, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

l=ggplot(data = winequality, aes(color, calidad, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

m=ggplot(data = winequality, aes(color, bueno, fill=color)) +  geom_boxplot(alpha=0.3)+  theme(legend.position="none", axis.title.x = element_blank())

plot_grid(a,b,c,d, ncol=2, nrow=2)
plot_grid(e,f,g,h, ncol=2, nrow=2)
plot_grid(i,j,k,l, ncol=2, nrow=2)
```
Ahora presentamos una tabla de contingencia y su reresentaci贸n gr谩fica para analizar la asociaci贸n entre la variable color, que nos indica el tipo de vino (blanco o tinto), y la variable bueno.

```{r tabla de contingencia, echo=FALSE, message=FALSE, warning=FALSE}
xtabs(~ color + bueno, data = winequality)
cross_plot(data=winequality, input=c("color"), target="bueno")
```


```{r eliminar objetos, message=FALSE, warning=FALSE, include=FALSE}
rm(list = c("a","b","c","d","e","f","g","h","i","j","k","l","m"))
```

<!-- Igual que el chunk anterior pero con un c贸digo m谩s sencillo y m谩s limpio -->
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(DataExplorer)
plot_boxplot(winequality, by="color", ncol=2, nrow=2, ggtheme = theme_minimal(), theme_config = list(
  "plot.background" = element_rect(fill = "yellow"),
  "aspect.ratio" = 1))
```


## 3. Correlaciones {#correlaciones}

A continuaci贸n observamos la correlaci贸n entre las variables. Los tres asteriscos (***) indican que la correlaci贸n es significativa al 99% de confianza, mientras que dos representan un 95% y un asterisco indica un 90% de confianza. 


```{r convertimos las columnas a num茅ricas, include=FALSE}
winequality$color = as.numeric(winequality$color)
winequality$bueno= as.numeric(winequality$bueno)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#An谩lisis de correlaci贸n entre las variables num茅ricas o cuantitativas.
numericas = winequality %>% dplyr::select(where(is.numeric))


corrplot.mixed(round(
  cor(numericas),1),
  upper = "shade",
  lower = "number",
  tl.pos = "lt",
  addCoef.col = "black",
  number.cex = .6
)

#Una vez calculados los coeficientes de correlaci贸n, es conveniente ver su significancia y los gr谩ficos d dispersi贸n de la correlaci贸n entre las variables a trav茅s de la funci贸n chart.correlation().
chart.Correlation(numericas, histogram = F, pch= 3)
```

Hemos observado una fuerte correlaci贸n entre las variables "calidad" y bueno", por lo que procedemos a eliminar ambas variables.
```{r eliminar variable correlacionada, include=FALSE}
winequality$bueno=NULL
winequality$calidad= NULL
```



# 4. Algoritmos de clasificaci贸n: Divisi贸n, ajuste y evaluaci贸n {#algoritmos}

Llegados a este punto, dividimos {#division} el conjunto de datos entre una muestra de entrenamiento, compuesta por el 70%, y una muestra de test, compuesta por el 30% restante. El m茅todo de partici贸n para entrenar los algoritmos ser谩 un cross-validation de 5 conjuntos y una sola repetici贸n.

A continuaci贸n presentamos una peque帽a explicaci贸n de los algoritmos usados, los par谩metros {#parametros} espec铆ficos de cada uno de ellos y los resultados obtenidos. 


```
Si quieres profundizar en detalles t茅cnicos puedes consultar el c贸digo en mi enlace de GitHub.
```

```{r include=FALSE}
set.seed(155)
winequality$color= as.factor(winequality$color)
levels(winequality$color)= c("blanco", "rojo")
# ndice de partici贸n

indice_particion=createDataPartition(winequality$color, p=0.7, list=F)

# Muestras de entrenamiento y test
entrenamiento = winequality [indice_particion,]
test= winequality[-indice_particion,]
```



```{r echo=FALSE}
# Hiperpar谩metros de caret
fiveStats = function(...) c ( twoClassSummary(...), defaultSummary(...) )
control <- trainControl( method = "repeatedcv", 
                         number = 5,
                         repeats = 1, 
                         classProbs = TRUE, 
                         summaryFunction = fiveStats,
                         returnResamp = "final",
                         allowParallel = TRUE )
metrica <- "ROC"
```


## 4.1.rbol de decisi贸n

Los 谩rboles de decisi贸n son modelos predictivos formados por reglas binarias (si/no) con las que se consigue repartir las observaciones en funci贸n de sus atributos y predecir as铆 el valor de la variable respuesta.

>Algoritmo usado: 'adaboost', donde tenemos que especificar el n煤mero de iteraciones (nIter).

```{r include=FALSE}
set.seed( 55 )

clusterCPU <- makePSOCKcluster(detectCores()-1)
registerDoParallel(clusterCPU)

Grid_ada <-  expand.grid(nIter = c(200,350), method = c("adaboost"))

mod_ada <- train(color ~ ., data = entrenamiento, 
              method = "adaboost", 
              metric = metrica, 
              #preProc = c("center", "scale"), 
              trControl = control,
              tuneGrid = Grid_ada)

stopCluster(clusterCPU)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(mod_ada)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
prediccion_ada <- predict( mod_ada, test )
cf.gbm=confusionMatrix( prediccion_ada, test$color )
cf.gbm
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
CrossTable(prediccion_ada, test$color , prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE)
```

    

```{r echo=FALSE, message=FALSE, warning=FALSE}
roc_ada= roc(test$color,as.numeric(prediccion_ada))
ggroc(roc_ada, aes="linetype",legacy.axes = TRUE, colour="green") +
  geom_abline() +
  theme_light()
```



## 4.2.Random forest

Son modelos basados en la combinaci贸n de 谩rboles de decisi贸n independientes generados a partir de un vector de muestreo aleatorio que usa la misma distribuci贸n para todos los 谩rboles de estudio. Consigue mejores resultados gracias a que genera un amplio n煤mero de 谩rboles no correlacionados y posteriormente los promedia.


>Algoritmo usado = 'cforest', v谩lido para problemas de clasificaci贸n y regresi贸n y d贸nde debemos configurar el n煤mero de predictores seleccionados aleatoriamente en cada 谩rbol (mtry).

```{r include=FALSE}
set.seed( 55 )
clusterCPU <- makePSOCKcluster(detectCores()-1)
registerDoParallel(clusterCPU)

Grid_rf <-  expand.grid(mtry=c(1:5))

mod_rf <- train(color ~ ., data = entrenamiento, 
              method = "cforest", 
              metric = metrica, 
              #preProc = c("center", "scale"), 
              trControl = control,
              tuneGrid = Grid_rf)

stopCluster(clusterCPU)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(mod_rf)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
prediccion_rf <- predict( mod_rf, test )
cf.gbm=confusionMatrix( prediccion_rf, test$color )
cf.gbm
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
CrossTable(prediccion_rf, test$color , prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE)
```

    

```{r echo=FALSE, message=FALSE, warning=FALSE}
roc_rf= roc(test$color,as.numeric(prediccion_rf))
ggroc(roc_rf, aes="linetype",legacy.axes = TRUE, colour="green") +
  geom_abline() +
  theme_light()
```


## 4.3.M谩quinas de vector soporte

Es un algoritmo de aprendizaje supervisado que realiza un mapeo no lineal de los datos de entrenamiento para asignarlos a un espacio de mayor dimensi贸n en el que puede realizarse una regresi贸n lineal mediante funciones n煤cleo o kernel. La aplicaci贸n de M谩quinas de Vectores Soporte para resolver tanto problemas de clasificaci贸n como de regresi贸n se ha incrementado notablemente debido, fundamentalmente, a su alto rendimiento de forma general y su capacidad para modelar relaciones no lineales.

>Algoritmo usado: 'svmRadial', d贸nde debemos ajustar el coste, un hiperpar谩metro que controla la penalizaci贸n que se aplica a las clasificaciones err贸neas cuando se entrena el modelo (C). Si su valor es alto, el modelo resultante es m谩s flexible y se ajusta mejor a las observaciones de entrenamiento, pero con el riesgo de overfitting. Tambi茅n debemos asignar valor para sigma (sigma), que es el coeficiente del kernel radial.

```{r include=FALSE}
set.seed( 55 )
clusterCPU <- makePSOCKcluster(detectCores()-1)
registerDoParallel(clusterCPU)

Grid_svm <-  expand.grid(sigma = c(0.0100, 0.0125,0.015,0.15), C = c(0.1,0.5,1))

mod_svm <- train(color ~ ., data = entrenamiento, 
              method = "svmRadial", 
              metric = metrica, 
              #preProc = c("center", "scale"), 
              trControl = control,
              tuneGrid = Grid_svm)

stopCluster(clusterCPU)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(mod_svm)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
prediccion_svm <- predict( mod_svm, test )
cf.gbm=confusionMatrix( prediccion_svm, test$color )
cf.gbm
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
CrossTable(prediccion_svm, test$color , prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE)
```

    

```{r echo=FALSE, message=FALSE, warning=FALSE}
roc_svm= roc(test$color,as.numeric(prediccion_svm))
ggroc(roc_svm, aes="linetype",legacy.axes = TRUE, colour="green") +
  geom_abline() +
  theme_light()
```


## 4.4.Red neuronal

Las redes neuronales son algoritmos de aprendizaje que tratan de emular el comportamiento del cerebro humano, recibiendo una informaci贸n (capa de entrada) que es procesada y se transmite a las posteriores capas. Permite resolver problemas que no son linealmente separables. 
En esta familia de algoritmos cobra gran importancia el concepto del Gradiente Descendente que se usa para optimizar la funci贸n objetivo, en concreto trata de encontrar el m铆nimo de la funci贸n de forma iterativa.

>Algoritmo usado: 'mlpWeightDecayML'. Debemos definir el n煤mero de neuronas en cada capa oculta (layer) y la tasa de aprendizaje o tasa de variaci贸n de los pesos (decay).

En esta versi贸n se usan 2 capas ocultas y una tasa de aprendizaje, que controla la rapidez con la que el modelo se adapta al problema. Una tasa de aprendizaje demasiado grande puede resultar en oscilaciones demasiad elevadas durante el entrenamiento. Por el contrario, una tasa demasiado peque帽a puede hacer que el modelo se atasque en una soluci贸n sub贸ptima, o incluso que nunca llegue a converger.
```{r message=FALSE, warning=FALSE, cache=T, include=FALSE}
library(caret)
library(parallelly)
set.seed( 55 )
clusterCPU <- makePSOCKcluster(detectCores()-1)
registerDoParallel(clusterCPU)

Grid_nn <-  expand.grid(layer1=c(1:10), layer2= c(0:4), layer3=0, decay= c(0.05,0.1,0.15))
mod_nn <- train(color ~ ., data = entrenamiento, 
              method = "mlpWeightDecayML", 
              metric = "kappa", 
              #preProc = c("center", "scale"), 
              trControl = control,
              tuneGrid = Grid_nn)

stopCluster(clusterCPU)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(mod_nn)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
prediccion_nn <- predict( mod_nn, test )
cf.gbm=confusionMatrix( prediccion_nn, test$color )
cf.gbm
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
CrossTable(prediccion_nn, test$color , prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE)
```

    

```{r echo=FALSE, message=FALSE, warning=FALSE}
roc_nn= roc(test$color,as.numeric(prediccion_nn))
ggroc(roc_nn, aes="linetype",legacy.axes = TRUE, colour="green") +
  geom_abline() +
  theme_light()
```




## 4.5. Gradient Boosting

El Gradient Boosting se fundamenta combinando el uso de algoritmos basados en boosting con los procedimientos de optimizaci贸n del gradiente.

El concepto de descenso del gradiente ha sido introducido en el apartado de la red neuronal. Por otra parte, el boosting es un m茅todo de clasificaci贸n que pertenece a las t茅cnicas de ensemble o multiclasificadores, las cu谩les son una combinaci贸n de dos o m谩s clasificadores que, generalmente, proporciona estimaciones m谩s robustas y eficientes. Tambi茅n se utilizan porque resuelven el problema de sobre-adaptaci贸n (overfitting) y es posible obtener buenos resultados con pocos datos.

>Algoritmo usado: 'gbm'. Debemos decidir el n煤mero de iteraciones del algoritmo de boosting (n.trees). Cuanto mayor es el valor otorgado, menor es el error de entrenamiento, pero podemos caer en problemas de overfitting. Tambi茅n debemos definir la profundidad o divisiones de los 谩rboles (interaction.depth). Asimismo, debemos controlar la influencia que tiene cada modelo sobre el conjunto de ensemble (shinkrage) y el n煤mero m铆nimo de observaciones que debe tener un nodo para ser dividido (n.minobsinnode).

```{r include=FALSE}
set.seed( 55 )
clusterCPU <- makePSOCKcluster(detectCores()-1)
registerDoParallel(clusterCPU)

tune_grid <- expand.grid(n.trees = seq(from = 200, to = 500, by = 50),
                         interaction.depth = c(1, 2, 3, 4),
                         shrinkage = 0.1,
                         n.minobsinnode = 10)
mod_GBM <- train(entrenamiento[ , -c(12)], 
                 entrenamiento$color,
                 method = "gbm",
                 metric = metrica,
                 trControl = control,
                 tuneGrid = tune_grid)
stopCluster(clusterCPU)
```



```{r echo=FALSE}
plot(mod_GBM)
```


```{r echo=FALSE}
prediccion_GBM <- predict( mod_GBM, test )
cf.gbm=confusionMatrix( prediccion_GBM, test$color )
cf.gbm
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
CrossTable(prediccion_GBM, test$color , prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE)
```

    


```{r echo=FALSE, message=FALSE, warning=FALSE}
roc_GBM= roc(test$color,as.numeric(prediccion_GBM))
ggroc(roc_GBM, aes="linetype",legacy.axes = TRUE, colour="green") +
  geom_abline() +
  theme_light()
```

# 5. 驴Qu茅 importancia otorga cada modelo a cada variable? {#importancia}


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(gbm)
#plot(varImp(unlist(mod_ada)))
plot(varImp(mod_rf), main ="Importancia de las variables seg煤n Random forest")
#plot(varImp(mod_svm))
#plot(varImp(mod_nn))
plot(varImp(mod_GBM), main = "Importancia de las variables seg煤n Gradient Boosting")
```


# 6. Comparativa de modelos {#metricas}

En este apartado realizamos una comparaci贸n de las distintas m茅tricas en cada uno de los modelos realizados y observamos si existen diferencias significativas en los resultados de dichos modelos.
```{r message=FALSE, warning=FALSE, include=FALSE}
Result <- function ( modelos ){
  n_modelos = length(modelos)
  comparativa <- matrix(0, n_modelos, 7)
  pred <- NULL

  for (i in 1:n_modelos){
    pred[[i]] <- predict(modelos[i], test, type="prob")
    comparativa[i,1] = modelos[[i]]$method

       comparativa[i,2] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("ROC")]
       comparativa[i,3] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Sens")]
       comparativa[i,4] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Spec")]
       comparativa[i,5] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Accuracy")]
       comparativa[i,6] = modelos[[i]]$results[rownames(modelos[[i]]$bestTune), c("Kappa")]
    
    comparativa[i,7] = auc(roc(test$color,pred[[i]][[1]][,"blanco"]))
  }
  colnames(comparativa) <- c("Modelo", "AUC", "Sens", "Spec", "Accuracy", "Kappa", "AUC test")
  return(comparativa)
}
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
modelos <- list(mod_ada = mod_ada,
                mod_rf = mod_rf, 
                mod_nn = mod_nn,
                mod_svm = mod_svm, 
                mod_GBM= mod_GBM)


Comparativa <- as.data.frame(Result (modelos))

Comparativa$Modelo= as.factor(Comparativa$Modelo)
Comparativa= Comparativa %>% mutate_if(is.character, as.numeric)

Comparativa[2:7]= round(Comparativa[2:7], digits = 4 )
datatable(Comparativa)
```

A continuaci贸n se presenta una tabla con los resultados de entrenamiento de cada modelo. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
resultados <- resamples(modelos)
summary(resultados)
```

Seguidamente se muestra un diagrama de cajas con los resultados de cada modelo de entrenamiento.
```{r echo=FALSE, message=FALSE, warning=FALSE}
dotplot(resultados)
```

Finalmente, mediante la correcci贸n de Bonferroni se comprobar谩 la hip贸tesis nula de que no existen diferencias de modelos. Aquellos cruces de modelos que presenten p-valores menores a 0.05 indicar谩n que s铆 existen diferencias entre ambos modelos.

```{r echo=FALSE, message=FALSE, warning=FALSE}
diferencias <- diff(resultados)
summary(diferencias)
```


# Anexo I: Etapas en un proceso de *machine learning* {#anexo1}


Conviene prestar atenci贸n a las siguientes etapas para llevar a cabo problemas de predicci贸n mediante t茅cnicas de *machine learning*:

* **[Definir el problema](#problema)** . 

* Explorar las **[caracter铆sticas de los datos](#caracteristicas)** . 

* **Preprocesado** {#preprocesado}: Consiste en realizar las transformaciones necesarias para que los datos puedan ser interpretados por el algoritmo. Dichas transformaciones depender谩n de las caracter铆sticas  observadas de los datos y de los algoritmos a usar. 
En nuestro caso, no ha sido necesario aplicar ninguna transformaci贸n. Sin embargo, la realidad suele ser distinta, por lo que es habitual encontrarse ante conjuntos de datos donde las caracter铆sticas de 茅stos nos obliguen a realizarles diversas manipulaciones con el fin de que puedan ser interpretados por los modelos. Suele tratarse de la parte m谩s laboriosa y an谩rquica de un proceso de machine learning, ya que la adecuaci贸n y el orden de cada t茅cnica depender谩 de cada caso concreto. [En el anexo II](#anexo2) puedes encontrar algunas de las dificultades m谩s habituales en el preprocesado.

* **[Divisi贸n de la muestra](#division)** . Para poder evaluar la calidad predictiva de un modelo, es necesario examinarlo con un conjunto de datos independiente. Antes de ello, para entender la divisi贸n de la muestra, debemos comprender las fases necesarias de un modelo de *Machine Learning*:

  +  Fase de entrenamiento: Estimar los par谩metros del modelo.

  +  Fase de validaci贸n: Ajustar el modelo para obtener los mejores resultados basados en una m茅trica. Es decir, se decide cu谩l de las m茅tricas se decide priorizar. 

  +  Fase de test: Comprobar el comportamiento del modelo.

En ocasiones, se entrena un modelo con un conjunto de datos distinto a los datos de validaci贸n. Sin embargo, generalmente se usa el mismo conjunto y se suele aplicar un sistema de validaci贸n llamado validaci贸n cruzada o *cross validated* [^1], que consiste en dividir el conjunto de entrenamiento en k particiones, repetir el procedimiento de entrenamiento y validaci贸n k veces, de forma que en cada una de ellas se entrene el modelo con k-1 particiones y se eval煤e con la partici贸n restante. 

[^1]: Existen otros tipos de sistemas de validaci贸n que tambi茅n acuden a estrategias de *resampling* con el fin de no usar un conjunto independiente de datos sino un subconjunto de los datos de entrenamiento. Ejemplos de ello son el *Leave-One-Out Cross-Validation* (LOOCV), el *repeated Cross validation*, *Boostraping*. Puedes ampliar en el anexo 4 de la siguiente p谩gina web: [https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret#Anexos]

As铆, de incorporar m茅todos de validaci贸n basados en *resampling* [^2] el conjunto de datos se divide entre una muestra de entrenamiento y una muestra de test, de manera que cada observaci贸n solamente puede aparecer en una de las anteriores muestras. Generalmente la divisi贸n es de un 70-80% los datos de entrenamiento y un 20-30% los datos de test.

[^2]:En caso contrario, debemos dividir la muestra en 3 conjuntos: entrenamiento, validaci贸n y test. 

* **[Definici贸n de hiper-par谩metros](#parametros)**  En este paso se define el m茅todo de *resampling*, explicado en el punto anterior, y el n煤mero de repeticiones. Ambas decisiones est谩n relacionadas y se realizan atendiendo, principalmente, a 2 factores: el coste computacional y la reproducibilidad en la creaci贸n de particiones (tama帽o de la muestra y desbalanceo de clases). Tambi茅n se definen los par谩metros espec铆ficos de cada modelo. Existen 3 tipos de b煤squeda de hiper-par谩metros: 

  +  Grid Search: Se especifican los valores que se quieren evaluar. Para realizar dicho m茅todo se requiere de un conocimiento previo y experiencia resolviendo problemas similiares con datos similares. 

  +  Random search: Se realiza una b煤squeda aleatoria dentro de un rango determinado. El problema de dicho m茅todo es que puede aumentar de manera considerable el coste computacional.

  +  Adaptative Resampling: Se alcanza el 贸ptimo despu茅s de un gradual ajuste probando distintos par谩metros. No siempre funciona pero cuenta con la ventaja de un bajo coste computacional.

* **[M茅tricas](#metricas)** : Evaluar la capacidad predictora de los algoritmos usados en la muestra de test. En general, para problemas de clasificaci贸n se usa accuracy y para problemas de regresi贸n el RMSE. Estas son las m茅tricas m谩s comunes para problemas de clasificaci贸n:

  +  **Accuracy**: La accuracy de un clasificador es el cociente entre el n煤mero de ejemplos que correctamente clasificados entre el total de instancias.

  +  **Kappa**: Es una medida estad铆stica cuyo rango es [-1,1] que determina la precisi贸n del modelo ajustando su valor a la probabilidad de acierto esperado de la clase positiva. Es una medida m谩s robusta para tratar con clases desbalanceadas, ya que descuenta la probabilidad de acertar al azar.
  
  + **Precision**: Es el porcentaje de aciertos entre los que se ha predicho la clase positiva. Es decir, los verdaderos positivos dividido los verdaderos positivos + los falsos positivos.

  +  **Sensitivity / recall**: La sensibilidad es la probabilidad de clasificar correctamente una observaci贸n cuyo estado real sea la presencia de clase positiva / mayoritaria. En nuestro caso, la probabilidad de clasificar correctamente los vinos blancos.

  +  **Spectificity**: La especificidad se define como la probabilidad de clasificar correctamente a un individuo cuyo estado real sea la ausencia de la condici贸n. En el presente caso, la probabilidad de clasificar correctamente los vinos tintos.
  
  + **F1-score**:Se define como la media arm贸nica de la precisi贸n y la sensibilidad/recall. El objetivo del F1-score es combinar las m茅tricas de precisi贸n y recall en una sola m茅trica. Asimismo, el F1-score ha sido dise帽ado para funcionar bien con datos desequilibrados.
  
  +  **curvas ROC**: No es propiamente una m茅trica sino una representaci贸n gr谩fica del rendimiento de un modelo en un problema de clasificaci贸n binario. Nos da informaci贸n acerca de c贸mo var铆a la relaci贸n de verdaderos positivos y verdaderos negativos dependiendo del corte de probabilidad usado.
  
  +  **AUC** (Area under the ROC curve): Es el 谩rea bajo la curva ROC. Este estad铆stico muestra la capacidad del modelo para distinguir ambas clases. 
  
  
  + Adem谩s, la **matriz de confusi贸n ** nos permite conocer la distribuci贸n del error a lo largo de las clases.

* En problemas de regresi贸n, las m茅tricas a tener en cuenta son las siguientes:

  +  **MSE**: *Mean squared error*. Es la media de los errores al cuadrado.

  +  **RMSE**: *Root mean squared error*. Es lo mismo que la anterior pero no est谩 en unidades al cuadrado, sin贸 que sus unidades son iguales a las de la variable respuesta, lo que facilita su interpretaci贸n.

  +  **MAE**: *Mean absolute error*. La media de los errores en valor absoluto. Al no elevar el error al cuadrado, no penaliza tanto las grandes desviaciones, lo cual resulta beneficia aquellos modelos que predicen muy bien la mayor铆a de observaciones pero cometen grandes desviaciones en otras.

# Anexo II: Dificultades habituales en el preprocesado {#anexo2}

Como coment谩bamos en l铆neas anteriores, el [preprocesado](#preprocesado) suele ser la parte m谩s larga de un proceso de aprendizaje autom谩tico, y aunque en esta ocasi贸n no ha sido necesario realizar grandes transformaciones a los datos, lo normal es encontrarse ante conjuntos de datos donde las caracter铆sticas de 茅stos nos obliguen a realizarles diversas manipulaciones para que puedan ser interpretados por los modelos. Estos casos pueden ser:


* A veces, es adecuado aplicar transformaciones a las variables para que aporten mayor informaci贸n al modelo o para que puedan ser interpretadas por 茅ste --> Transformaci贸n a logaritmos cuando tenemos datos asim茅tricos, discretizaci贸n de variables cuando queremos limitar los valores de una variable num茅rica, creaci贸n de *dummies* cuando queremos recoger la presencia o ausencia de una caracter铆stica. Adem谩s, en la mayor铆a de veces es conveniente centrar y escalar los datos para los algoritmos de *machine learning*. 

* Casos donde tenemos filas o columnas con datos ausentes --> Podemos realizar una imputaci贸n de datos (existen diversos m茅todos), no hacer nada (algunos modelos permiten valores NA), o bien proceder a la eliminaci贸n, ya sea de la variable que presenta muchos faltantes o de la observaci贸n. La adecuaci贸n de cada posibilidad depende del objetivo a resolver y de la calidad del dato.

* Desbalanceo de clases: Casos donde se presentan muy pocos valores de un nivel, por lo que no tenemos datos suficientes para que en la fase de entrenamiento el modelo reconozca los patrones de dicha clase. Por ejemplo: Tenemos una base con datos sanitarios de pacientes y queremos desarrollar un modelo que clasifique al individuo dependiendo de si tiene c谩ncer o no. Imaginemos que tenemos una variable que recoge si el paciente se realiz贸 alg煤n chequeo en los 煤ltimos 6 meses, pero el 96% de los pacientes tienen un valor de "no"--> Equilibrado de la muestra mediante un aumento de la clase minoritaria o una disminuci贸n de la clase mayoritaria.

* Tratamiento de valores at铆picos --> Dependiendo del tama帽o muestral y del objetivo perseguido, podemos eliminar dichos datos, sustituirlos por el valor m谩ximo/m铆nimo admitido o dejarlos como est谩n.

* Selecci贸n de las variables: Las variables pueden ser descartadas por distintos motivos: Varianza pr贸xima a 0, gran porcentaje de datos ausentes, insignificancia de la variable, multicolinealidad, etc.


* Conjunto de datos con elevado n煤mero de variables --> Cuando disponemos de demasiadas variables puede resultar conveniente realizar t茅cnicas de reducci贸n de dimensiones c贸mo el an谩lisis de componentes principales, el an谩lisis factorial, etc. Dichas t茅cnicas se basan en crear nuevas variables compuestas por la informaci贸n de varias variables, reduciendo as铆 el n煤mero de total de 茅stas. 


